
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<link rel="shortcut icon" type="image/x-icon" href="teasers/favicon.ico" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
<title>Wei Peng | Stanford University</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="js/hidebib.js"></script>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-40545479-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


</head>

<body>
  <div class="container">
    <table width="900" border="0" align="center" cellpadding="20">
      <table width="90%" align="center" border="0" cellpadding="10">
        <tr>
          <td width="70%" valign="top">
            <p align="center">&nbsp;</p>

            <p align="center"><font size="6px">Wei Peng | Stanford University</font><br>
            wepeng@stanford.edu or Wei.Peng@oulu.fi</p>

            <p>I am a Postdoctoral Researcher at <a href="http://cnslab.stanford.edu/">CNSlab, Stanford University</a>. 
              I received my PhD from <a href="https://www.oulu.fi/en"> University of Oulu </a>, Finland, 
              where I was advised by Academy Professor <a href="https://gyzhao-nm.github.io/Guoying/">Guoying Zhao</a>. During my PhD study, I was lucky enough to have the opportunity 
              to visit <a href="https://hms.harvard.edu/">Harvard Medical School</a> and <a href="https://vision.ee.ethz.ch/">CVL, ETH Zurich</a>. Prior to that, 
              I received the B.E. degree from <a href="https://en.uestc.edu.cn/" target="_blank">UESTC</a>, China, and Master degree from <a href="https://en.xmu.edu.cn/" target="_blank">Xiamen University</a>, China.
              My research interests include Machine Learning, Geometric neural networks, Medical image analysis with special emphasis on Neuroscience.
.</p>

            <p> <a href="https://www.linkedin.com/in/wei-peng-464bb1136/" target="_blank" ><img src="icons/linkedIn.png" height="36"></a> / 
                <a href="https://scholar.google.com/citations?user=TDFM0QYAAAAJ&hl=en" target="_blank"><img src="icons/google_scholar.png" height="26"></a> /
                <a href="https://github.com/xiaoiker" target="_blank" ><img src="icons/github_alt.png" height="26"></a> / 
                <a href="https://www.zhihu.com/people/ikerpeng" target="_blank" ><img src="icons/zhihu.png" height="26"></a> /
              
            </p>
          </td>
          <td width="30%">
            <div class="instructorphoto">
              <img onmouseover="document.getElementById('georgia').src='teasers/me_in_crazy.JPG';"
              onmouseout="document.getElementById('georgia').src='icons/cv2.png';"src="icons/cv2.png" id="georgia">
            </div>
          </td>
        </tr>
      </table>
    </table>
  </div>
  <br>

  <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>News</h2>
      <div class="news">
        <ul> 
          <li><span> [2022.11] We just release a Benchmark for <a href="https://github.com/tvaranka/meb">Micro-Experssion Recognition (MER)</a>.</span></li>
          <li><span> [2022.08] An invited talk about Hyperbolic Neural Networks at <a href="https://sai.jlu.edu.cn/info/1035/3437.htm">Jilin university, China</a> .</span></li>
          <li><span> [2022.05] Our paper won the '<strong> 2022 ISMRM Magna Cum Laude Merit Award </strong>', the list can be found <a href="https://www.ismrm.org/22/22-Magna.pdf">here</a>.</span></li>
          <li><span> [2022.04] I have successfully defended my doctoral thesis with a grade of '<strong> Excellent </strong>'. The thesis can be downloaded <a href="http://jultika.oulu.fi/Record/isbn978-952-62-3259-1">here</a>.</span></li>
          <li><span> [2022.03] Our paper about MRI Acceleration is accepted by CVPR 2022.</span></li>
          <li><span> [2022.02] Our abstract about MRI Acceleration is accepted by ISMRM 2022 (Oral).</span></li> 
          <li><span> [2022.01] Our Survey paper about Hyperbolic neural networks is accepted by TPAMI 2022. </span></li> 
          <li><span> [2021.10] I will visit <a href="https://vision.ee.ethz.ch/">CVL, ETH Zurich</a> for four months.</span></li>
          <li><span> [2021.03] Our ICCV'19 paper on rPPG has been granted <a href="https://site.ieee.org/finland/activities/awards/best-student-paper-award/">IEEE Finland Section best conference paper award 2020 </a>. </span></li> 
          <li><span> [2021.01] I will visit <a href="https://hms.harvard.edu/">Harvard Medical School</a> for six months.</span></li> 
          <li><span> [2020.08] We got the 2nd Place on Action Recognition Track of <a href="https://vipriors.github.io/2020/">ECCV 2020 VIPriors Challenges</a>.</span></li> 
        </ul>
      </div>
    </table>
  </div>
  <br>

  <div class="container">
    <h2> Publications </h2>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/mri.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/abs/2204.02480"><b>Learning Optimal K-space Acquisition and Reconstruction using Physics-Informed Neural Networks</b></a><br>
          <strong>Wei Peng</strong>, Li Feng, Guoying Zhao, Fang Liu. <em> Computer Vision and Pattern Recognition (CVPR)</em>, 2022. <br>
         
        </td> 
        </td>
      </table>
    </div>
  
  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/mri.gif" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/abs/2204.02480"><b> (Abstruct) Learning Optimal K-space Acquisition and Reconstruction using Physics-Informed Neural Networks</b></a><br>
          <strong>Wei Peng</strong>, Li Feng, Guoying Zhao, Fang Liu. <em> ISMRM </em>, 2022. <br>
         
        </td> 
        </td>
      </table>
    </div>
  
  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/hyperbolic.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/abs/2101.04562"><b>Hyperbolic Deep Neural Networks: A Survey</b></a><br>
          <strong>Wei Peng</strong>, Tuomas Varanka, Abdelrahman Mostafa, Henglin Shi, Guoying Zhao. <em> IEEE Transactions on Pattern Analysis & Machine Intelligence(T-PAMI)</em>, 2022. <br>
          <a href="https://github.com/xiaoiker/Awesome-Hyperbolic-NeuralNetworks">Code</a>
        </td> 
        </td>
      </table>
    </div>
  
  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/pose.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Intrinsic-Extrinsic_Preserved_GANs_for_Unsupervised_3D_Pose_Transfer_ICCV_2021_paper.pdf"><b>Intrinsic-extrinsic preserved gans for unsupervised 3D pose transfer</b></a><br>
          Haoyu Chen, Hao Tang, Henglin Shi, <strong>Wei Peng</strong>, Nicu Sebe, Guoying Zhao. <em> IEEE International Conference on Computer Vision (ICCV)</em>, 2021. <br>
          <a href="https://github.com/mikecheninoulu/Unsupervised_IEPGAN">Code</a>
        </td> 
        </td>
      </table>
    </div>
  

  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/tripool.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://www.sciencedirect.com/science/article/pii/S0031320321001084"><b>Tripool: Graph triplet pooling for 3D skeleton-based action recognition</b></a><br>
          <strong>Wei Peng</strong>, Xiaopeng Hong, Guoying Zhao. <em> Pattern Recognition (PR)</em>, 2021. <br>
        </td> 
        </td>
      </table>
    </div>

  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/poincare.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/abs/2007.15678"><b>Mix Dimension in Poincar\'{e} Geometry for 3D Skeleton-based Action Recognition</b></a><br>
          <strong>Wei Peng</strong>, Jingang Shi, Zhaoqiang Xia, Guoying Zhao. <em> Proceedings of the 28th ACM International Conference on Multimedia (ACM MM)</em>, 2020. <br>
        </td> 
        </td>
      </table>
    </div>

<div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/mer.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2006.09674"><b>Revealing the Invisible with Model and Data Shrinking for Composite-database Micro-expression Recognition</b></a><br>
          Zhaoqiang Xia, <strong>Wei Peng</strong>, Huai-Qian Khor, Xiaoyi Feng, Guoying Zhao. <em> IEEE Transactions on Image Processing (TIP)</em>, 2020. <br>
        </td> 
        </td>
      </table>
    </div>

  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/nas_gcn.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/5652/5508"><b>Learning graph convolutional network for skeleton-based human action recognition by neural searching</b></a><br>
          <strong>Wei Peng</strong>, Xiaopeng Hong, Haoyu Chen, Guoying Zhao. <em> The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI)</em>, 2020. <br>
           <a href="https://github.com/xiaoiker/GCN-NAS">Code</a>
        </td> 
        </td>
      </table>
    </div>

 <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/rppg.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Remote_Heart_Rate_Measurement_From_Highly_Compressed_Facial_Videos_An_ICCV_2019_paper.pdf"><b>Remote Heart Rate Measurement from Highly Compressed Facial Videos: an End-to-end Deep Learning Solution with Video Enhancement</b></a><br>
          Zitong Yu*, <strong>Wei Peng*</strong>, Xiaobai Li, Xiaopeng Hong, Guoying Zhao. <em> IEEE International Conference on Computer Vision (ICCV)</em>, 2019. <br>
           <a href="https://github.com/xiaoiker/GCN-NAS">Code</a>
        </td> 
        </td>
      </table>
    </div>
    <hr>

   <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>Academic Activities</h2>
      <h3>Academic Reviewer: </h3>
      <div class="Academic Activities">
        <ul> 
         <li><span> Invited as Reviewer for cnoferences, including CVPR2023, ICASSP2023, etc.</span></li>
          <li><span> Invited as Reviewer for Scientific Reports - Nature </span></li>
          <li><span> Invited as Reviewer for IEEE Transactions on Multimedia</span></li>
          <li><span> Invited as Reviewer for IEEE Transactions on Image Processing</span></li>
          <li><span> Invited as Reviewer for Pattern Recognition </span></li>
         <li><span> Invited as Reviewer for cnoferences, including NeurIPS2022, CVPR2023, 2022, AAAI2022, ICML2022, MICCAI2022, etc.</span></li>
        </ul>
      </div>
    </table>
  </div>
  <br>


<div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>Teaching Assistant</h2>
      <div class="Teaching">
        <ul> 
          <li><span> <a href="https://web.stanford.edu/class/psyc221/">Machine Learning for Neuroimaging</a>, Stanford Univerisity -- Fall 2022 </span></li> 
          <li><span> Affective computing, Univerisity of Oulu -- Fall 2020</span></li>
        </ul>
      </div>
    </table>
  </div>
  <br>
  
<!-- 
  <div class="container">
    <h2> Teaching </h2>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="60%" valign="center">
          <p>
            <a><b>Affective computing - Fall 2020 </a></b><br>
          </p>
        </td>
      </table>
    </div>
    <p style="text-align:right;">Stolen from <a href="https://gkioxari.github.io/">Georgia Gkioxari</a></p>

  </div>
  <br> -->


<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

          
</body>
</html>
